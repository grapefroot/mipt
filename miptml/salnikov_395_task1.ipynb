{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ ФИВТ: Курс Машинное Обучение (осень, 2016), Арсений Ашуха, ars.ashuha@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Organization Info</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "- Hastie, The Elements of Statistical Learning, https://goo.gl/k3wfEU\n",
    "    - 2.9 Model Selection and the Bias–Variance Tradeoff \n",
    "    - 15 Random Forests\n",
    "- Соколов, Семинары по композиционным методам, https://goo.gl/sn8RyJ\n",
    "- Andrew Ng, Bias vs. Variance, https://goo.gl/1ISZ6Y\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall <номер_группы> <фамилия>``, к примеру -- ``ML2016_fall 401 ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb``, к примеру -- ``ivanov_401_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Мы используем автоматические фильтры, и просто не найдем ваше дз, если вы не аккуратно его подпишите.\n",
    "- **PS2**: Напоминаем, что дедлайны жесткие, письма пришедшие после автоматически удаляются =( чтобы соблазна не было "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Check Questions</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответе на вопросы своими словами (загугленный материал надо пересказать), ответ обоснуйте (напишите и ОБЪЯСНИТЕ формулки если потребуется), если не выходит, то вернитесь к лекции дополнительным материалам:\n",
    "\n",
    "**Вопрос 1**: Какие формулы у шума, смещения, разброса? Какой смысл у этих компонент?\n",
    "\n",
    "Шум - $E_{x,y}(a^*(x)-y)^2$ - неустранимая ошибка\n",
    "\n",
    "\n",
    "Смещение - $E_{x,y}(\\bar{a}(x) - a^*(x))^2$ - недостаточная гибкость статистического метода для данной реальной задачи\n",
    "\n",
    "\n",
    "Разброс - $E_{x, y}E_{X^l}(\\mu(X^l)(x) - \\bar{a}(x))^2$ - величина, показывающая как изменилась бы оценка при использовании другой обучающей выборки\n",
    "\n",
    "**Вопрос 2**: 4. Приведите пример семейства с маленьким смещением и большим разбросом. Приведите пример семейства с большим смещением и маленьким разбросом.\n",
    "\n",
    "1) полиномы большой степени\n",
    "2) приближение константной функцией\n",
    "\n",
    "\n",
    "**Вопрос 3**: Как сгенерировать подвыборку с помощью бутстрапа?\n",
    "\n",
    "Выборка с возвращениями\n",
    "\n",
    "**Вопрос 4**: Что такое бэггинг?\n",
    "\n",
    "Мета алгоритм, объединяющий несколько базовых алгоритмов и обучающий их на выборках из исходных данных с повторениями. \n",
    "Позволяет уменьшить дисперсию(смещение)\n",
    "\n",
    "**Вопрос 5**:  Как соотносятся смещение разброс композиции, построенной с помощью бэггинга, со смещением и разбросом одного базового алгоритма?\n",
    "\n",
    "$\\sigma_{bagging} = \\sigma_{base} \\div$ number of base algorithms\n",
    "\n",
    "**Вопрос 6**: Как обучается случайный лес? В чем отличия от обычной процедуры построения решающих деревьев?\n",
    "\n",
    "Случайный лес = бэггинг над деревьями с количеством признаков равных $\\sqrt(n)$, где $n$ - количество признаков\n",
    "\n",
    "**Вопрос 7**: Почему хорошими базовыми алгоритмами для бэггинга являются именно деревья?\n",
    "\n",
    "Бэггинг позволяет уменьшить высокий разброс(variance), часто встречающийся у деревьев. \n",
    "\n",
    "**Вопрос 8**: Как оценить качество случайного леса с помощью out-of-bag-процедуры?\n",
    "\n",
    "Считать ошибку на тех данных, которые не использовались при построении конкретных дерерьев. При условии того что выборка производится равномерно с повторениями, всегда будет достаточное количество деревьев для оценки.\n",
    "\n",
    "-----------\n",
    "PS: Если проверяющий не понял ответ на большинство вопросов, то будет пичалька. Пишите так, чтобы можно было разобраться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Bagging</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Известно, что бэггинг плохо работает, если в качестве базовых классификаторов взять knn. Попробуем понять причины на простом примере.\n",
    "\n",
    "Пусть дана выборка $X^l$ из $l$ объектов с ответами из множества $Y = \\{−1, +1\\}$. Будем рассматривать классификатор одного ближайшего соседа в качестве базового алгоритма. Построим с помощью бэггинга композицию длины $N$:\n",
    "\n",
    "$$a_N(x) = sign(\\sum_{n=1}^{N} b_n(x))$$\n",
    "\n",
    "Оцените вероятность того, что ответ композиции на произвольном объекте x будет\n",
    "отличаться от ответа одного классификатора ближайшего соседа, обученного по всей\n",
    "выборке. Покажите, что эта вероятность стремится к нулю при N → ∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**<Решение>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Bagging Implementation</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте беггинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from numpy.random import choice\n",
    "import multiprocessing\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "class BaggingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator, n_estimators, items_rate=1.0, features_rate=1.0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: sklearn.Classifier\n",
    "            Базовый алгоритм, который можно обучить (есть метод fit).\n",
    "            Для обучение композиции нужно много таких, можэно получить с помощю copy.deepcopy\n",
    "\n",
    "        n_estimators: int\n",
    "            Число алгоритмов в композиции\n",
    "\n",
    "        items_rate: float > 0\n",
    "            Доля объектов из трейна, на которой будет обучаться каждый базовый алгоритм\n",
    "\n",
    "        features_rate: float > 0\n",
    "            Доля фичей, на которой будет обучаться и применяться каждый базовый алгоритм\n",
    "        \"\"\"\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.items_rate = items_rate\n",
    "        self.features_rate = features_rate\n",
    "        \n",
    "        self.trained = False\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Метод должен обучить композицию алгоритмов, используя X, y как обучающую выборку.\n",
    "        Не забудте реализорвать функционал выбора случайных объектов и фичей.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array\n",
    "        y: 1d np.array\n",
    "        \"\"\"\n",
    "        # Тут храните обученные базовые алгоритмы\n",
    "        self.estimators = []\n",
    "        # Тут храните фичи для каждого алгоритма\n",
    "        self.features_idx = []\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            estimator = deepcopy(self.base_estimator)\n",
    "            # =======================================\n",
    "            # Обучите базовые алгоритмы\n",
    "            # =======================================\n",
    "            \n",
    "            objects_subsample_size = (X.shape[0]) * self.items_rate\n",
    "            features_subset_size = (X.shape[1]) * self.features_rate\n",
    "\n",
    "            object_indecies = choice(X.shape[0], size=objects_subsample_size, replace=True)\n",
    "            feature_indecies = choice(X.shape[1], size=features_subset_size, replace=True)\n",
    "            \n",
    "            self.features_idx.append(feature_indecies)\n",
    "        \n",
    "#             estimator.fit(X[np.ix_(object_indecies, feature_indecies)], y[np.ix_(object_indecies)])\n",
    "            estimator.fit(X[object_indecies[:, np.newaxis], feature_indecies], y[np.ix_(object_indecies)])\n",
    "            self.estimators.append(estimator)\n",
    "            \n",
    "        self.trained = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: 2d np.array матрица объекты признаки на которых нужно сказать ответ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred: 1d np.array, Вектор классов для каждого объекта\n",
    "        \"\"\"\n",
    "        if not self.trained:\n",
    "            raise Exception('Bagging classifier instance is not fitted yet')\n",
    "        \n",
    "        probs = [] # Храните тут ответы каждого базового алгоритма\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # =======================================\n",
    "            # Получите ответы (вероятности) от всех базовых алгоритмов\n",
    "            # ======================================\n",
    "            probs.append(self.estimators[i].predict_proba(X[:, self.features_idx[i]]))\n",
    "        \n",
    "        # =======================================\n",
    "        # Усредните вероятности полученные от базовых алгоритмов\n",
    "        # =======================================\n",
    "        \n",
    "        y_pred = np.argmax((np.mean(probs, axis=0)), axis=1)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "titanic = pd.read_csv('./data/train.csv')[['Survived', 'Pclass', 'Sex', 'Age', 'Fare']]\n",
    "\n",
    "sex_encoder = LabelEncoder()\n",
    "titanic.Sex = sex_encoder.fit_transform(titanic.Sex)\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = titanic[features].values, titanic.Survived.values\n",
    "X = np.nan_to_num(X)\n",
    "X_train, y_train, X_test, y_test = X[:500], y[:500], X[500:], y[500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно обучить свой беггинг на датасете титаник, и посмотреть работает ли он. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree classifier:  0.988 0.744245524297\n",
      "bagging over decision tree classifiers:  0.9 0.81074168798\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier с 10 моделями\n",
    "# =======================================\n",
    "tree_estimator = DecisionTreeClassifier()\n",
    "dectree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print 'decision tree classifier: ', accuracy_score(dectree.predict(X_train), y_train), accuracy_score(dectree.predict(X_test), y_test)\n",
    "clf = BaggingClassifier(base_estimator=tree_estimator, n_estimators=500, items_rate=0.5, features_rate=0.5).fit(X_train, y_train)\n",
    "print 'bagging over decision tree classifiers: ', accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите эксперименты:\n",
    "    - Работает-ли беггинг лучше чем просто линейная модель?\n",
    "    - Какой items_rate и features_rate работает лучше и почему?\n",
    "    \n",
    "    На тестовой выборке лучше работает модель в которое применяется бэггинг. Feature importnance обычно используется sqrt(p). В данном случае лучше всего работает 2(это и есть sqrt(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  (0.94599999999999995, 0.80562659846547313)\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier с 100 моделями\n",
    "# =======================================\n",
    "clf = BaggingClassifier(base_estimator=tree_estimator, n_estimators=100).fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print 'accuracy score: ',acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  (0.80000000000000004, 0.76982097186700771)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# =======================================\n",
    "# Обучите LogsiticRegression \n",
    "# =======================================\n",
    "clf = LogisticRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print 'accuracy score: ',acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult = pd.read_csv(\n",
    "    './data/adult.data', \n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"], \n",
    "    header=None, na_values=\"?\")\n",
    "\n",
    "adult = pd.get_dummies(adult)\n",
    "adult[\"Target\"] = adult[\"Target_ >50K\"]\n",
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "X_train, y_train, X_test, y_test = X[:20000], y[:20000], X[20000:], y[20000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответте на вопросы:\n",
    "    - Работает-ли беггинг лучше чем просто линейная модель?\n",
    "    - Какой items_rate и features_rate работает лучше и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  (0.99890000000000001, 0.86314783854788635)\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier с 100 моделями\n",
    "# =======================================\n",
    "clf = BaggingClassifier(base_estimator=tree_estimator, n_estimators=100).fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print 'accuracy score: ',acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  (0.79990000000000006, 0.79515962104927951)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# =======================================\n",
    "# Обучите LogsiticRegression \n",
    "# =======================================\n",
    "clf = LogisticRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "acc = accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)\n",
    "print 'accuracy score: ',acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Text, Image Classification</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше в каждом эксперименте нужно: \n",
    "- сравниться с линейной моделью ( какую лучше выбрать?=) )\n",
    "- сделать выбор в пользу одной из моделей\n",
    "- выбор обосновать, почему одна из моделей хуже а другая лучше\n",
    "- что такое хуже и лучше\n",
    "- попробуйте беггинг над деревьями и линейными моделями \n",
    "- почему работает или не работает, какие особенности данных на это влияют"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train, y_train = vectorizer.fit_transform(newsgroups_train.data), newsgroups_train.target\n",
    "X_test,  y_test  = vectorizer.transform(newsgroups_test.data), newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969860350009 0.827934147637\n",
      "CPU times: user 1min 6s, sys: 3.39 s, total: 1min 9s\n",
      "Wall time: 8.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите Линейную модель \n",
    "# =======================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861233869542 0.608470525757\n",
      "CPU times: user 46 s, sys: 11.9 ms, total: 46 s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier\n",
    "# =======================================\n",
    "\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10, items_rate=0.25, features_rate=1).fit(X_train, y_train)\n",
    "print accuracy_score(clf.predict(X_train), y_train), accuracy_score(clf.predict(X_test), y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import load_cifar10\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10('./data/cifar10/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.reshape(X_train.shape[0], -1), X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите Линейную модель \n",
    "# =======================================z\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# =======================================\n",
    "# Обучите беггинг над DecisionTreeClassifier\n",
    "# =======================================\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), 10, items_rate=0.2, features_rate=1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Random Forest Feature Impotance</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Опишите как вычисляется важность фичей в дереве, можите изучить как работает  feature\\_importances_ в sklearn.\n",
    "\n",
    "---\n",
    "для оценки важности используется индекс Джини. Если индекс Джини узла близок к нулю, то соответствующий узел преимущественно содержит наблюдения какого-то одного класса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Почитайте Feature Impotance для Adult и Titanic (используйте полный датасет), ПРОИНТЕРПРЕТИРУЙТЕ резульататы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "X_train, y_train, X_test, y_test = X[:20000], y[:20000], X[20000:], y[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n",
    "                        items_rate=1, features_rate=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Посчитайте feature_importances для clf\n",
    "# ======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult_importances = np.mean(map(lambda x: x.feature_importances_, clf.estimators), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Race_ Amer-Indian-Eskimo', 0.020462400522731808),\n",
       " ('Occupation_ Exec-managerial', 0.0199271186530844),\n",
       " ('Education_ Doctorate', 0.017537260024433704),\n",
       " ('Age', 0.016648117260472738),\n",
       " ('Country_ Poland', 0.016565288467848834),\n",
       " ('Country_ Nicaragua', 0.016078652581235649),\n",
       " ('Education_ HS-grad', 0.016037997356101584),\n",
       " ('Education_ 10th', 0.015376381740498917),\n",
       " ('Workclass_ Self-emp-inc', 0.014587979820718628),\n",
       " ('Hours per week', 0.014550315448816959),\n",
       " ('Relationship_ Other-relative', 0.014331277205771249),\n",
       " ('Occupation_ Farming-fishing', 0.014066328166179547),\n",
       " ('Country_ Vietnam', 0.01397189063690704),\n",
       " ('Occupation_ Handlers-cleaners', 0.013929154987706549),\n",
       " ('Country_ Cuba', 0.013820480552612641),\n",
       " ('Sex_ Male', 0.013053581505165496),\n",
       " ('Education_ 7th-8th', 0.01296437144989792),\n",
       " ('Country_ Germany', 0.012841001408222974),\n",
       " ('Workclass_ Private', 0.012802858791706619),\n",
       " ('Country_ El-Salvador', 0.012724065610112188),\n",
       " ('Martial Status_ Never-married', 0.012492373175825789),\n",
       " ('Martial Status_ Divorced', 0.012112696430321266),\n",
       " ('Country_ Jamaica', 0.011991783532853849),\n",
       " ('Country_ Columbia', 0.011732073834170083),\n",
       " ('Education_ Masters', 0.011723134908468156),\n",
       " ('Country_ Greece', 0.011299362906063546),\n",
       " ('Country_ Philippines', 0.01128426830726436),\n",
       " ('Workclass_ Self-emp-not-inc', 0.010784086567430034),\n",
       " ('Workclass_ ?', 0.010539553953793756),\n",
       " ('Occupation_ Machine-op-inspct', 0.010512405824815933),\n",
       " ('Country_ Hong', 0.010506586762459391),\n",
       " ('Race_ White', 0.010468042326813245),\n",
       " ('Education_ 12th', 0.010391096002107365),\n",
       " ('Martial Status_ Married-spouse-absent', 0.010379245520384394),\n",
       " ('Country_ Portugal', 0.010353490535907516),\n",
       " ('Country_ England', 0.010291289117192331),\n",
       " ('Country_ Dominican-Republic', 0.01023639327642103),\n",
       " ('Occupation_ Tech-support', 0.0098359256265046751),\n",
       " ('Occupation_ Adm-clerical', 0.009670206316467719),\n",
       " ('Occupation_ Prof-specialty', 0.0094705478473096766),\n",
       " ('Occupation_ Transport-moving', 0.0094438739651548295),\n",
       " ('Occupation_ Sales', 0.0093321255976731438),\n",
       " ('Workclass_ Never-worked', 0.0092031360546432333),\n",
       " ('Education_ Assoc-acdm', 0.0091653902866914456),\n",
       " ('Country_ Laos', 0.0091364953754597151),\n",
       " ('Country_ France', 0.0091329178267112957),\n",
       " ('Country_ United-States', 0.0090691617411719893),\n",
       " ('Country_ Italy', 0.008957044523529481),\n",
       " ('Capital Gain', 0.008892705500717751),\n",
       " ('Occupation_ Priv-house-serv', 0.008816955341057647),\n",
       " ('Country_ Outlying-US(Guam-USVI-etc)', 0.0087879292998047798),\n",
       " ('Country_ Yugoslavia', 0.0087822597155975696),\n",
       " ('Country_ Taiwan', 0.0087538495196826608),\n",
       " ('Relationship_ Wife', 0.0085696285242065802),\n",
       " ('Country_ Puerto-Rico', 0.0084518908518722465),\n",
       " ('Education_ 1st-4th', 0.0083667130779049442),\n",
       " ('Martial Status_ Separated', 0.0083074713017886222),\n",
       " ('Occupation_ Other-service', 0.0082526042040622655),\n",
       " ('Relationship_ Not-in-family', 0.0081977954228881853),\n",
       " ('Occupation_ Armed-Forces', 0.0081914622107722782),\n",
       " ('Martial Status_ Married-civ-spouse', 0.0081227237756595523),\n",
       " ('Education-Num', 0.0080774531205205797),\n",
       " ('Capital Loss', 0.0080195103585074708),\n",
       " ('Relationship_ Unmarried', 0.0079457135132927886),\n",
       " ('Race_ Asian-Pac-Islander', 0.0077821898941442536),\n",
       " ('Education_ Assoc-voc', 0.0076860093907755471),\n",
       " ('Country_ China', 0.0076342147681457261),\n",
       " ('Country_ Haiti', 0.0076168339393338814),\n",
       " ('Martial Status_ Married-AF-spouse', 0.0075649917087138776),\n",
       " ('Education_ 11th', 0.0073747762121450667),\n",
       " ('Martial Status_ Widowed', 0.0073327854545081764),\n",
       " ('Country_ Scotland', 0.0073203948913879088),\n",
       " ('Country_ Iran', 0.0072045275431504843),\n",
       " ('Relationship_ Own-child', 0.0071795370313521342),\n",
       " ('Occupation_ Protective-serv', 0.0071757925742974397),\n",
       " ('Education_ Bachelors', 0.0071492818673770161),\n",
       " ('Country_ Hungary', 0.0071442566520788075),\n",
       " ('Sex_ Female', 0.0071207367701455167),\n",
       " ('Education_ 5th-6th', 0.0070774446028545679),\n",
       " ('Country_ Ireland', 0.0070519785162043592),\n",
       " ('Country_ Ecuador', 0.0069867175407442575),\n",
       " ('Country_ Japan', 0.0069352308200309855),\n",
       " ('Country_ Trinadad&Tobago', 0.0068720461202840645),\n",
       " ('Occupation_ Craft-repair', 0.0068285592350837299),\n",
       " ('Education_ Some-college', 0.0067652561140424342),\n",
       " ('Country_ Holand-Netherlands', 0.006742212282518094),\n",
       " ('Country_ Honduras', 0.0067401108714643344),\n",
       " ('Country_ Guatemala', 0.0066912906020316658),\n",
       " ('Occupation_ ?', 0.0065890386850103897),\n",
       " ('Country_ ?', 0.0064921628252068344),\n",
       " ('fnlwgt', 0.0062538788343244178),\n",
       " ('Race_ Other', 0.0059661426348232519),\n",
       " ('Workclass_ Without-pay', 0.005749879566046303),\n",
       " ('Workclass_ State-gov', 0.005524023924206394),\n",
       " ('Country_ India', 0.005522690758054883),\n",
       " ('Race_ Black', 0.005515252606953602),\n",
       " ('Workclass_ Local-gov', 0.0054814691320786016),\n",
       " ('Education_ Preschool', 0.0053558932827792258),\n",
       " ('Relationship_ Husband', 0.0051135373838803368),\n",
       " ('Country_ Canada', 0.0050449632212533927),\n",
       " ('Country_ Peru', 0.00495414720919012),\n",
       " ('Country_ South', 0.0045586197199910415),\n",
       " ('Education_ 9th', 0.004384912952370537),\n",
       " ('Country_ Mexico', 0.0043112023012039143),\n",
       " ('Country_ Cambodia', 0.0040190176943811669),\n",
       " ('Workclass_ Federal-gov', 0.0037720265043436952),\n",
       " ('Country_ Thailand', 0.0035975280896325961),\n",
       " ('Education_ Prof-school', 0.0034885411992843472)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(adult.columns, adult_importances), key=lambda (x,y):y, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = titanic[features].values, titanic.Survived.values\n",
    "X = np.nan_to_num(X)\n",
    "X_train, y_train, X_test, y_test = X[:500], y[:500], X[500:], y[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n",
    "                        items_rate=1, features_rate=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Посчитайте feature_importances для clf\n",
    "# ======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_importances = np.mean(map(lambda x: x.feature_importances_, clf.estimators), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sex', 0.0062538788343244178),\n",
       " ('Age', 0.0080774531205205797),\n",
       " ('Fare', 0.008892705500717751),\n",
       " ('Pclass', 0.016648117260472738)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(['Pclass', 'Sex', 'Age', 'Fare'], adult_importances), key=lambda (x,y):y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
